{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to the Day 2 Lab!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get started --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ffe36f",
   "metadata": {},
   "source": [
    "## First - let's talk about the Chat Completions API\n",
    "\n",
    "1. The simplest way to call an LLM\n",
    "2. It's called Chat Completions because it's saying: \"here is a conversation, please predict what should come next\"\n",
    "3. The Chat Completions API was invented by OpenAI, but it's so popular that everybody uses it!\n",
    "\n",
    "### We will start by calling OpenAI again - but don't worry non-OpenAI people, your time is coming!\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e38f17a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:51:43.869763Z",
     "start_time": "2025-11-14T17:51:43.867141Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "97846274",
   "metadata": {},
   "source": [
    "## Do you know what an Endpoint is?\n",
    "\n",
    "If not, please review the Technical Foundations guide in the guides folder\n",
    "\n",
    "And, here is an endpoint that might interest you..."
   ]
  },
  {
   "cell_type": "code",
   "id": "5af5c188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:51:43.898458Z",
     "start_time": "2025-11-14T17:51:43.886047Z"
    }
   },
   "source": [
    "import requests\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
    "payload = {\n",
    "    \"model\": \"gpt-5-nano\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a fun fact\"}]\n",
    "}\n",
    "payload"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-5-nano',\n",
       " 'messages': [{'role': 'user', 'content': 'Tell me a fun fact'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "2d0ab242",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:51:51.767389Z",
     "start_time": "2025-11-14T17:51:43.942745Z"
    }
   },
   "source": [
    "response = requests.post(\n",
    "    \"https://api.openai.com/v1/chat/completions\",\n",
    "    headers=headers,\n",
    "    json=payload\n",
    ")\n",
    "response.json()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-CbsFV2r0ls2oXxDTESRxr09B3XjtT',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1763142705,\n",
       " 'model': 'gpt-5-nano-2025-08-07',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Fun fact: A day on Venus is longer than a year on Venus. It takes about 243 Earth days to rotate once, but only about 225 days to complete an orbit around the Sun. Want another fun fact?',\n",
       "    'refusal': None,\n",
       "    'annotations': []},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 11,\n",
       "  'completion_tokens': 822,\n",
       "  'total_tokens': 833,\n",
       "  'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
       "  'completion_tokens_details': {'reasoning_tokens': 768,\n",
       "   'audio_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0}},\n",
       " 'service_tier': 'default',\n",
       " 'system_fingerprint': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "cb11a9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:51:51.860140Z",
     "start_time": "2025-11-14T17:51:51.857647Z"
    }
   },
   "source": [
    "response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fun fact: A day on Venus is longer than a year on Venus. It takes about 243 Earth days to rotate once, but only about 225 days to complete an orbit around the Sun. Want another fun fact?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:51:51.908720Z",
     "start_time": "2025-11-14T17:51:51.906013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ollama_api = \"http://localhost:11434/api/chat\"\n",
    "ollama_headers = {\"Content-Type\": \"application/json\"}\n",
    "ollama_model = \"gpt-oss:120b\"\n",
    "ollama_payload = {\n",
    "    \"model\": ollama_model,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a fun fact\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False\n",
    "}\n",
    "ollama_payload"
   ],
   "id": "a62d81797fb9dad1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-oss:120b',\n",
       " 'messages': [{'role': 'user', 'content': 'Tell me a fun fact'}],\n",
       " 'stream': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:52:07.355488Z",
     "start_time": "2025-11-14T17:51:51.955111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ollama_response = requests.post(\n",
    "    ollama_api,\n",
    "    headers=ollama_headers,\n",
    "    json=ollama_payload\n",
    ")\n",
    "ollama_response.json()"
   ],
   "id": "952914ce37331dc3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gpt-oss:120b',\n",
       " 'created_at': '2025-11-14T17:52:07.350459424Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': '**Fun Fact:**\\u202fA single honeybee can visit up to **5,000 flowers** in one day‚Äîand in its lifetime it will have made just enough honey to feed **its own weight** in sugar! üêùüå∏\\n\\nHoneybees are incredibly efficient pollinators. While they‚Äôre buzzing from bloom to bloom, they not only gather nectar and pollen for the hive, they also help fertilize the plants they visit, making a huge contribution to the world‚Äôs food supply. So next time you see a bee, remember it‚Äôs a tiny, winged superhero working around the clock!',\n",
       "  'thinking': 'User asks \"Tell me a fun fact\". Simple. Provide a fun fact, maybe about something interesting. Should be concise but engaging. Possibly include explanation. Let\\'s give a fun fact.'},\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'total_duration': 15393481159,\n",
       " 'load_duration': 155083140,\n",
       " 'prompt_eval_count': 72,\n",
       " 'prompt_eval_duration': 92222020,\n",
       " 'eval_count': 169,\n",
       " 'eval_duration': 15072003883}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:52:07.477573Z",
     "start_time": "2025-11-14T17:52:07.475359Z"
    }
   },
   "cell_type": "code",
   "source": "ollama_response.json()[\"message\"][\"content\"]",
   "id": "583c1d0313a6efe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Fun Fact:**\\u202fA single honeybee can visit up to **5,000 flowers** in one day‚Äîand in its lifetime it will have made just enough honey to feed **its own weight** in sugar! üêùüå∏\\n\\nHoneybees are incredibly efficient pollinators. While they‚Äôre buzzing from bloom to bloom, they not only gather nectar and pollen for the hive, they also help fertilize the plants they visit, making a huge contribution to the world‚Äôs food supply. So next time you see a bee, remember it‚Äôs a tiny, winged superhero working around the clock!'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "cea3026a",
   "metadata": {},
   "source": [
    "# What is the openai package?\n",
    "\n",
    "It's known as a Python Client Library.\n",
    "\n",
    "It's nothing more than a wrapper around making this exact call to the http endpoint.\n",
    "\n",
    "It just allows you to work with nice Python code instead of messing around with janky json objects.\n",
    "\n",
    "But that's it. It's open-source and lightweight. Some people think it contains OpenAI model code - it doesn't!\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "490fdf09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:52:12.648695Z",
     "start_time": "2025-11-14T17:52:07.552634Z"
    }
   },
   "source": [
    "# Create OpenAI client\n",
    "from openai import OpenAI\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\n",
    "response.choices[0].message.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fun fact: Honey never spoils. Archaeologists have found pots of honey in ancient Egyptian tombs over 3,000 years old that are still perfectly edible, thanks to honey‚Äôs low water content and natural acidity.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "c7739cda",
   "metadata": {},
   "source": [
    "## And then this great thing happened:\n",
    "\n",
    "OpenAI's Chat Completions API was so popular, that the other model providers created endpoints that are identical.\n",
    "\n",
    "They are known as the \"OpenAI Compatible Endpoints\".\n",
    "\n",
    "For example, google made one here: https://generativelanguage.googleapis.com/v1beta/openai/\n",
    "\n",
    "And OpenAI decided to be kind: they said, hey, you can just use the same client library that we made for GPT. We'll allow you to specify a different endpoint URL and a different key, to use another provider.\n",
    "\n",
    "So you can use:\n",
    "\n",
    "```python\n",
    "gemini = OpenAI(base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\", api_key=\"AIz....\")\n",
    "gemini.chat.completions.create(...)\n",
    "```\n",
    "\n",
    "And to be clear - even though OpenAI is in the code, we're only using this lightweight python client library to call the endpoint - there's no OpenAI model involved here.\n",
    "\n",
    "If you're confused, please review Guide 9 in the Guides folder!\n",
    "\n",
    "And now let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "id": "f74293bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:52:12.702216Z",
     "start_time": "2025-11-14T17:52:12.699807Z"
    }
   },
   "source": [
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not google_api_key.startswith(\"AIz\"):\n",
    "    print(\"An API key was found, but it doesn't start AIz\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:56:30.654602Z",
     "start_time": "2025-11-14T17:56:30.652398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gemini = OpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-pro\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\n",
    "response.choices[0].message.content"
   ],
   "id": "98a81a7a1c177d61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The man who voices Winnie the Pooh (Jim Cummings) also voices Tigger.\\n\\nThis means that in many scenes where the two characters are talking to each other, he's actually just having a conversation with himself in two completely different voices.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "65272432",
   "metadata": {},
   "source": [
    "## And Ollama also gives an OpenAI compatible endpoint\n",
    "\n",
    "...and it's on your local machine!\n",
    "\n",
    "If the next cell doesn't print \"Ollama is running\" then please open a terminal and run `ollama serve`"
   ]
  },
  {
   "cell_type": "code",
   "id": "f06280ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:52:58.077772Z",
     "start_time": "2025-11-14T17:52:58.074322Z"
    }
   },
   "source": [
    "requests.get(\"http://localhost:11434\").content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Ollama is running'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "c6ef3807",
   "metadata": {},
   "source": [
    "### Download llama3.2 from meta\n",
    "\n",
    "Change this to llama3.2:1b if your computer is smaller.\n",
    "\n",
    "Don't use llama3.3 or llama4! They are too big for your computer.."
   ]
  },
  {
   "cell_type": "code",
   "id": "e633481d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:53:11.745283Z",
     "start_time": "2025-11-14T17:53:11.054414Z"
    }
   },
   "source": [
    "!ollama pull llama3.2"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†ô \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†ô \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†∏ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest \u001B[K\r\n",
      "pulling dde5aa3fc5ff: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 2.0 GB                         \u001B[K\r\n",
      "pulling 966de95ca8a6: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.4 KB                         \u001B[K\r\n",
      "pulling fcc5a6bec9da: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 7.7 KB                         \u001B[K\r\n",
      "pulling a70ff7e570d9: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 6.0 KB                         \u001B[K\r\n",
      "pulling 56bb8bd477a5: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   96 B                         \u001B[K\r\n",
      "pulling 34bb5ab01051: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  561 B                         \u001B[K\r\n",
      "verifying sha256 digest \u001B[K\r\n",
      "writing manifest \u001B[K\r\n",
      "success \u001B[K\u001B[?25h\u001B[?2026l\r\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "d9419762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:53:13.867967Z",
     "start_time": "2025-11-14T17:53:13.860442Z"
    }
   },
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key='ollama')"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "e2456cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:53:22.623675Z",
     "start_time": "2025-11-14T17:53:17.382032Z"
    }
   },
   "source": [
    "# Get a fun fact\n",
    "response = ollama.chat.completions.create(model=\"llama3.2\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\n",
    "response.choices[0].message.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nDid you know that honey never spoils? Archaeologists have found pots of honey in ancient Egyptian tombs that are over 3,000 years old and still perfectly edible! Honey's longevity is due to its unique composition, which includes hydrogen peroxide that acts as a natural preservative. This makes it almost impossible for bacteria or other microorganisms to survive, preserving the honey's viability even after thousands of years.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "1e6cae7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:53:38.160703Z",
     "start_time": "2025-11-14T17:53:37.590304Z"
    }
   },
   "source": [
    "# Now let's try deepseek-r1:1.5b - this is DeepSeek \"distilled\" into Qwen from Alibaba Cloud\n",
    "!ollama pull deepseek-r1:1.5b"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†ô \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†π \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest \u001B[K\r\n",
      "pulling aabd4debf0c8: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.1 GB                         \u001B[K\r\n",
      "pulling c5ad996bda6e: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  556 B                         \u001B[K\r\n",
      "pulling 6e4c38e1172f: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.1 KB                         \u001B[K\r\n",
      "pulling f4d24e9138dd: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  148 B                         \u001B[K\r\n",
      "pulling a85fe2a2e58e: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  487 B                         \u001B[K\r\n",
      "verifying sha256 digest \u001B[K\r\n",
      "writing manifest \u001B[K\r\n",
      "success \u001B[K\u001B[?25h\u001B[?2026l\r\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "25002f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T17:53:41.792949Z",
     "start_time": "2025-11-14T17:53:40.314478Z"
    }
   },
   "source": [
    "response = ollama.chat.completions.create(model=\"deepseek-r1:1.5b\", messages=[{\"role\": \"user\", \"content\": \"Tell me a fun fact\"}])\n",
    "\n",
    "response.choices[0].message.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a fun fact for you: \\n\\nThe Andromeda Galaxy is the closest galaxy to our own Milky Way, and it's also our neighbor. It can be seen as a faint dot in the background when looking at the sky because we're on the opposite side of it from other stars. Its distance isn't too far compared to the universe! üòä\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
